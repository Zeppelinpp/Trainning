# è´¢åŠ¡åˆ†ææŠ¥å‘ŠReward Modelè®­ç»ƒé¡¹ç›®æ€»è§ˆ

## ğŸ¯ é¡¹ç›®ç›®æ ‡

è®­ç»ƒä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°è´¢åŠ¡åˆ†ææŠ¥å‘Šè´¨é‡çš„Reward Modelï¼Œåœ¨ä»¥ä¸‹ä¸‰ä¸ªç»´åº¦è¿›è¡Œæ‰“åˆ†ï¼š
1. **å‡†ç¡®åº¦ (Accuracy)**: è´¢åŠ¡æ•°æ®è®¡ç®—å’Œå¼•ç”¨çš„å‡†ç¡®æ€§
2. **ä¸“ä¸šåº¦ (Professionalism)**: ä¸“ä¸šæœ¯è¯­ä½¿ç”¨ã€æŠ¥å‘Šç»“æ„ã€è¯­è¨€è§„èŒƒæ€§
3. **åˆ†ææ·±åº¦ (Depth of Analysis)**: æ´å¯Ÿæ·±åº¦ã€å› æœåˆ†æã€å»ºè®®è´¨é‡

è¯¥æ¨¡å‹å¯ç”¨äºï¼š
- RLHF/RLAIFè®­ç»ƒçš„å¥–åŠ±ä¿¡å·
- è‡ªåŠ¨è¯„ä¼°ç”ŸæˆæŠ¥å‘Šè´¨é‡
- é«˜è´¨é‡æ•°æ®ç­›é€‰
- æŒç»­å­¦ä¹ å’Œæ¨¡å‹è¿­ä»£

---

## ğŸ“‹ æ¨èè®­ç»ƒæ¡†æ¶

### æ ¸å¿ƒæ¡†æ¶ç»„åˆ

| æ¡†æ¶ | ç‰ˆæœ¬ | ç”¨é€” | ä¼˜åŠ¿ |
|------|------|------|------|
| **PyTorch** | 2.0+ | æ·±åº¦å­¦ä¹ æ¡†æ¶ | çµæ´»ã€é«˜æ•ˆã€åŸç”Ÿåˆ†å¸ƒå¼æ”¯æŒ |
| **Transformers** | 4.35+ | é¢„è®­ç»ƒæ¨¡å‹åº“ | ä¸°å¯Œçš„æ¨¡å‹ã€ç»Ÿä¸€æ¥å£ |
| **DeepSpeed** | 0.12+ | å¤§æ¨¡å‹è®­ç»ƒä¼˜åŒ– | ZeROä¼˜åŒ–ã€æ˜¾å­˜æ•ˆç‡é«˜ |
| **Accelerate** | 0.24+ | åˆ†å¸ƒå¼è®­ç»ƒæŠ½è±¡ | ç®€åŒ–é…ç½®ã€æ˜“äºä½¿ç”¨ |
| **WandB** | 0.15+ | å®éªŒè·Ÿè¸ª | å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ |

### æ¡†æ¶å¯¹æ¯”

| ç‰¹æ€§ | PyTorch DDP | DeepSpeed | Megatron-LM |
|------|------------|-----------|-------------|
| æ˜“ç”¨æ€§ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| æ˜¾å­˜æ•ˆç‡ | â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| è®­ç»ƒé€Ÿåº¦ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| çµæ´»æ€§ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| é€‚ç”¨åœºæ™¯ | < 13Bæ¨¡å‹ | æ‰€æœ‰è§„æ¨¡ | > 20Bæ¨¡å‹ |

**æ¨èé€‰æ‹©**ï¼š
- **7Bä»¥ä¸‹æ¨¡å‹**: PyTorch DDP (åŸç”Ÿï¼Œç®€å•é«˜æ•ˆ)
- **7B-30Bæ¨¡å‹**: DeepSpeed ZeRO Stage 2
- **30Bä»¥ä¸Šæ¨¡å‹**: DeepSpeed ZeRO Stage 3 æˆ– Megatron-LM

---

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
Train/
â”œâ”€â”€ README.md                    # è‹±æ–‡æ–‡æ¡£ï¼ˆè¯¦ç»†è¯´æ˜ï¼‰
â”œâ”€â”€ å¿«é€Ÿå¼€å§‹.md                  # ä¸­æ–‡å¿«é€Ÿä¸Šæ‰‹æŒ‡å—
â”œâ”€â”€ PROJECT_OVERVIEW.md          # æœ¬æ–‡ä»¶ï¼šé¡¹ç›®æ€»è§ˆ
â”œâ”€â”€ requirements.txt             # Pythonä¾èµ–
â”œâ”€â”€ .gitignore                   # Gitå¿½ç•¥æ–‡ä»¶
â”‚
â”œâ”€â”€ config.yaml                  # è®­ç»ƒé…ç½®ï¼ˆæ ¸å¿ƒï¼‰
â”œâ”€â”€ deepspeed_config.json        # DeepSpeedé…ç½®
â”‚
â”œâ”€â”€ model.py                     # Reward Modelå®šä¹‰
â”‚   â”œâ”€â”€ FinancialRewardModel         (ç‚¹å¼è¯„åˆ†æ¨¡å‹)
â”‚   â””â”€â”€ PairwiseRewardModel          (æˆå¯¹æ¯”è¾ƒæ¨¡å‹)
â”‚
â”œâ”€â”€ dataset.py                   # æ•°æ®é›†åŠ è½½
â”‚   â”œâ”€â”€ FinancialRewardDataset
â”‚   â”œâ”€â”€ collate_fn_pointwise
â”‚   â””â”€â”€ collate_fn_pairwise
â”‚
â”œâ”€â”€ train.py                     # è®­ç»ƒè„šæœ¬ï¼ˆæ”¯æŒåˆ†å¸ƒå¼ï¼‰
â”‚   â””â”€â”€ RewardModelTrainer
â”‚
â”œâ”€â”€ evaluate.py                  # è¯„ä¼°è„šæœ¬
â”‚   â””â”€â”€ RewardModelEvaluator
â”‚
â”œâ”€â”€ inference.py                 # æ¨ç†è„šæœ¬
â”‚   â””â”€â”€ RewardModelInference
â”‚
â”œâ”€â”€ visualize_data.py            # æ•°æ®åˆ†æå·¥å…·
â”‚
â”œâ”€â”€ run_train.sh                 # è®­ç»ƒå¯åŠ¨è„šæœ¬
â”‚
â”œâ”€â”€ sample_report.json           # æ¨ç†æ ·ä¾‹è¾“å…¥
â”‚
â””â”€â”€ data/                        # æ•°æ®ç›®å½•
    â”œâ”€â”€ train.jsonl              # è®­ç»ƒé›† (5æ¡æ ·ä¾‹)
    â”œâ”€â”€ val.jsonl                # éªŒè¯é›† (1æ¡æ ·ä¾‹)
    â””â”€â”€ test.jsonl               # æµ‹è¯•é›† (1æ¡æ ·ä¾‹)
```

---

## ğŸ“Š æ ·ä¾‹æ•°æ®è¯´æ˜

### è®­ç»ƒé›†æ ·ä¾‹ (5æ¡)

| åºå· | ä¸»é¢˜ | æŠ¥å‘Šç±»å‹ | å‡†ç¡®åº¦ | ä¸“ä¸šåº¦ | æ·±åº¦ |
|------|------|---------|--------|--------|------|
| 1 | Q3å­£åº¦åˆ†æ | ç›ˆåˆ©èƒ½åŠ›åˆ†æ | 4.5 | 4.7 | 4.3 |
| 2 | å…¨å¹´åˆ†æ | èµ„äº§æ•ˆç‡&å¿å€ºèƒ½åŠ› | 4.8 | 4.9 | 4.7 |
| 3 | é£é™©è¯„ä¼° | è´¢åŠ¡é£é™©åˆ†æ | 4.6 | 4.8 | 4.9 |
| 4 | Q2ç¯æ¯”åˆ†æ | è´¢åŠ¡å˜åŒ–åˆ†æ | 4.4 | 4.5 | 4.2 |
| 5 | æŠ•èµ„å›æŠ¥ | ROE/ROICåˆ†æ | 4.7 | 4.8 | 4.8 |

**ç‰¹ç‚¹**ï¼š
- è¦†ç›–å¤šç§è´¢åŠ¡åˆ†æåœºæ™¯
- è¯„åˆ†æ ‡å‡†æ¸…æ™°
- æŠ¥å‘Šç»“æ„å®Œæ•´
- åŒ…å«å®é™…è´¢åŠ¡æ•°æ®

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
# æˆ–ä½¿ç”¨uvï¼ˆæ›´å¿«ï¼‰
uv pip install -r requirements.txt
```

### 2. æŸ¥çœ‹æ•°æ®

```bash
uv run visualize_data.py --data data/train.jsonl --check
```

### 3. è®­ç»ƒæ¨¡å‹

```bash
# å•å¡è®­ç»ƒ
uv run train.py --config config.yaml

# 4å¡åˆ†å¸ƒå¼è®­ç»ƒ
bash run_train.sh
```

### 4. è¯„ä¼°æ¨¡å‹

```bash
uv run evaluate.py \
    --checkpoint output/best_model \
    --config config.yaml \
    --test_file data/test.jsonl
```

### 5. æ¨ç†æµ‹è¯•

```bash
uv run inference.py \
    --checkpoint output/best_model \
    --config config.yaml \
    --input sample_report.json
```

---

## ğŸ”§ PyTorchåˆ†å¸ƒå¼è®­ç»ƒè¯¦è§£

### åŸç†æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Master Process                       â”‚
â”‚              (RANK=0, è´Ÿè´£åŒæ­¥)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”        â”Œâ”€â”€â”€â–¼â”€â”€â”€â”      â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
    â”‚ GPU 0 â”‚        â”‚ GPU 1 â”‚      â”‚ GPU 2 â”‚
    â”‚Modelâ‚€ â”‚        â”‚Modelâ‚ â”‚      â”‚Modelâ‚‚ â”‚
    â”‚Batchâ‚€ â”‚        â”‚Batchâ‚ â”‚      â”‚Batchâ‚‚ â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜        â””â”€â”€â”€â”¬â”€â”€â”€â”˜      â””â”€â”€â”€â”¬â”€â”€â”€â”˜
        â”‚                â”‚                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                   All-Reduceæ¢¯åº¦
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   åŒæ­¥æ›´æ–°æ‰€æœ‰æ¨¡å‹   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®æ¦‚å¿µ

| æ¦‚å¿µ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **RANK** | å…¨å±€è¿›ç¨‹ID | 4å¡è®­ç»ƒ: 0,1,2,3 |
| **LOCAL_RANK** | æœ¬åœ°GPU ID | å•æœº4å¡: 0,1,2,3 |
| **WORLD_SIZE** | æ€»è¿›ç¨‹æ•° | 4å¡è®­ç»ƒ: 4 |
| **Backend** | é€šä¿¡åç«¯ | NCCL (GPU), Gloo (CPU) |

### å¯åŠ¨æ–¹å¼å¯¹æ¯”

```bash
# æ–¹å¼1: torchrun (æ¨èï¼ŒPyTorch 1.10+)
torchrun --nproc_per_node=4 train.py --config config.yaml

# æ–¹å¼2: torch.distributed.launch (æ—§ç‰ˆ)
python -m torch.distributed.launch --nproc_per_node=4 train.py

# æ–¹å¼3: å¤šæœºè®­ç»ƒ
# ä¸»èŠ‚ç‚¹ (192.168.1.100)
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 \
    --master_addr=192.168.1.100 --master_port=29500 train.py

# ä»èŠ‚ç‚¹ (192.168.1.101)
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 \
    --master_addr=192.168.1.100 --master_port=29500 train.py
```

### æœ‰æ•ˆæ‰¹æ¬¡å¤§å°

```
çœŸå®batch_size = batch_size Ã— gradient_accumulation_steps Ã— num_gpus

ç¤ºä¾‹é…ç½®:
  batch_size: 4
  gradient_accumulation_steps: 4
  num_gpus: 4
  
æœ‰æ•ˆbatch_size = 4 Ã— 4 Ã— 4 = 64
```

---

## ğŸ“ˆ è®­ç»ƒé…ç½®å»ºè®®

### æ ¹æ®GPUæ˜¾å­˜é€‰æ‹©é…ç½®

| GPUæ˜¾å­˜ | åŸºåº§æ¨¡å‹ | Batch Size | Grad Accum | ç­–ç•¥ |
|---------|---------|-----------|------------|------|
| 24GB (3090/4090) | Qwen-7B | 2 | 8 | DDP |
| 40GB (A100) | Qwen-7B | 4 | 4 | DDP |
| 80GB (A100-80GB) | Qwen-7B | 8 | 2 | DDP |
| 24GB Ã— 4 | Qwen-7B | 4 | 4 | DDP |
| 24GB Ã— 4 | Qwen-14B | 2 | 8 | DeepSpeed ZeRO-2 |

### è¶…å‚æ•°è°ƒä¼˜å»ºè®®

```yaml
# åˆå§‹é…ç½®ï¼ˆä¿å®ˆï¼‰
learning_rate: 1e-5
warmup_ratio: 0.1
weight_decay: 0.01
num_epochs: 3

# å¦‚æœæ¬ æ‹Ÿåˆ
learning_rate: 2e-5  # æé«˜å­¦ä¹ ç‡
num_epochs: 5        # å¢åŠ è®­ç»ƒè½®æ•°

# å¦‚æœè¿‡æ‹Ÿåˆ
weight_decay: 0.05   # å¢åŠ æ­£åˆ™åŒ–
dropout: 0.2         # å¢åŠ dropout
```

---

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡è¯´æ˜

### æ ¸å¿ƒæŒ‡æ ‡

| æŒ‡æ ‡ | å«ä¹‰ | ç›®æ ‡å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **MSE** | å‡æ–¹è¯¯å·® | < 0.1 | é¢„æµ‹åˆ†æ•°ä¸çœŸå®åˆ†æ•°çš„å¹³æ–¹è¯¯å·® |
| **MAE** | å¹³å‡ç»å¯¹è¯¯å·® | < 0.3 | çº¦1.5åˆ†çš„è¯¯å·®ï¼ˆ5åˆ†åˆ¶ï¼‰ |
| **Pearsonç›¸å…³ç³»æ•°** | çº¿æ€§ç›¸å…³æ€§ | > 0.7 | é¢„æµ‹ä¸çœŸå®çš„çº¿æ€§ç›¸å…³ |
| **Spearmanç›¸å…³ç³»æ•°** | ç§©ç›¸å…³æ€§ | > 0.7 | é¢„æµ‹ä¸çœŸå®çš„æ’åºä¸€è‡´æ€§ |

### å„ç»´åº¦ç‹¬ç«‹è¯„ä¼°

```python
# è¯„ä¼°è¾“å‡ºç¤ºä¾‹
{
  "accuracy_mse": 0.085,
  "accuracy_pearson": 0.82,
  "professionalism_mse": 0.072,
  "professionalism_pearson": 0.85,
  "depth_of_analysis_mse": 0.095,
  "depth_of_analysis_pearson": 0.78,
  "overall_mse": 0.084,
  "overall_mae": 0.25
}
```

---

## ğŸ“ åç»­åº”ç”¨åœºæ™¯

### 1. RLHFè®­ç»ƒ

```python
# ä½¿ç”¨Reward Modelä½œä¸ºå¥–åŠ±ä¿¡å·
from transformers import AutoModelForCausalLM
from ppo_trainer import PPOTrainer

policy_model = AutoModelForCausalLM.from_pretrained("your-llm")
reward_model = load_reward_model("output/best_model")

trainer = PPOTrainer(
    model=policy_model,
    reward_model=reward_model,
    ...
)

trainer.train()
```

### 2. è´¨é‡è¯„ä¼°ç³»ç»Ÿ

```python
# æ‰¹é‡è¯„ä¼°ç”ŸæˆæŠ¥å‘Š
evaluator = RewardModelInference("output/best_model", "config.yaml")

for report in generated_reports:
    scores = evaluator.score_report(
        report['system_prompt'],
        report['input_data'],
        report['report']
    )
    
    # æ ¹æ®åˆ†æ•°è¿›è¡Œåˆ†çº§
    if scores['overall_score'] >= 4.5:
        tier = 'A+'  # ä¼˜ç§€
    elif scores['overall_score'] >= 4.0:
        tier = 'A'   # è‰¯å¥½
    else:
        tier = 'B'   # éœ€æ”¹è¿›
```

### 3. æ•°æ®ç­›é€‰

```python
# ä»å¤§é‡å¼±æ ‡æ³¨æ•°æ®ä¸­ç­›é€‰é«˜è´¨é‡æ ·æœ¬
high_quality_samples = []

for sample in weak_labeled_data:
    score = reward_model.score_report(...)
    
    if score['overall_score'] >= 4.5 and \
       score['scores']['accuracy'] >= 4.3:
        high_quality_samples.append(sample)

# ç”¨äºåç»­SFTè®­ç»ƒ
train_sft_model(high_quality_samples)
```

### 4. åœ¨çº¿å­¦ä¹ 

```python
# æŒç»­æ”¶é›†ç”¨æˆ·åé¦ˆï¼Œå®šæœŸé‡è®­ç»ƒ
def collect_feedback():
    user_ratings = get_user_ratings()
    return user_ratings

# æ¯å‘¨é‡è®­ç»ƒ
feedback_data = collect_feedback()
finetune_reward_model(feedback_data)
```

---

## ğŸ› ï¸ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### è®­ç»ƒé—®é¢˜

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| OOMï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰ | Batch sizeå¤ªå¤§ | å‡å°batch_sizeï¼Œå¢åŠ grad_accum |
| è®­ç»ƒæ…¢ | å•å¡è®­ç»ƒ | ä½¿ç”¨å¤šå¡DDPæˆ–DeepSpeed |
| Lossä¸ä¸‹é™ | å­¦ä¹ ç‡é—®é¢˜ | è°ƒæ•´å­¦ä¹ ç‡æˆ–warmup_ratio |
| æ¢¯åº¦çˆ†ç‚¸ | æ¢¯åº¦è£å‰ªå¤±æ•ˆ | æ£€æŸ¥max_grad_normè®¾ç½® |
| éªŒè¯é›†ä¸æ”¶æ•› | è¿‡æ‹Ÿåˆ | å¢åŠ weight_decayæˆ–dropout |

### æ•°æ®é—®é¢˜

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| æ•°æ®ä¸å¹³è¡¡ | æŸä¸ªåˆ†æ•°æ®µæ ·æœ¬è¿‡å¤š | æ•°æ®é‡é‡‡æ ·æˆ–åŠ æƒæŸå¤± |
| æ ‡æ³¨ä¸ä¸€è‡´ | æ ‡æ³¨å‘˜æ ‡å‡†ä¸ç»Ÿä¸€ | åˆ¶å®šè¯¦ç»†æ ‡æ³¨æŒ‡å— |
| æ•°æ®é‡ä¸è¶³ | æ ·æœ¬å¤ªå°‘ | æ•°æ®å¢å¼ºæˆ–ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ |

---

## ğŸ“š å‚è€ƒèµ„æº

### è®ºæ–‡

- **InstructGPT**: Training language models to follow instructions with human feedback
- **RLHF**: Fine-Tuning Language Models from Human Preferences
- **Constitutional AI**: Training a Helpful and Harmless Assistant with RLHF

### æ¡†æ¶æ–‡æ¡£

- [PyTorch Distributed Training](https://pytorch.org/tutorials/beginner/dist_overview.html)
- [DeepSpeed Documentation](https://www.deepspeed.ai/)
- [Transformers Documentation](https://huggingface.co/docs/transformers)

### ç›¸å…³é¡¹ç›®

- [trl](https://github.com/huggingface/trl): Transformer Reinforcement Learning
- [OpenRLHF](https://github.com/OpenLLMAI/OpenRLHF): å¼€æºRLHFæ¡†æ¶
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory): æ˜“ç”¨çš„LLMå¾®è°ƒæ¡†æ¶

---

## ğŸ“ æ£€æŸ¥æ¸…å•

### è®­ç»ƒå‰

- [ ] å·²å®‰è£…æ‰€æœ‰ä¾èµ–
- [ ] GPUé©±åŠ¨å’ŒCUDAæ­£å¸¸
- [ ] æ•°æ®æ ¼å¼æ­£ç¡®ï¼ˆä½¿ç”¨visualize_data.pyæ£€æŸ¥ï¼‰
- [ ] é…ç½®æ–‡ä»¶å·²æ ¹æ®ç¡¬ä»¶è°ƒæ•´
- [ ] æœ‰è¶³å¤Ÿçš„å­˜å‚¨ç©ºé—´ï¼ˆæ¨¡å‹+æ—¥å¿— > 20GBï¼‰

### è®­ç»ƒä¸­

- [ ] Lossæ­£å¸¸ä¸‹é™
- [ ] GPUåˆ©ç”¨ç‡ > 80%
- [ ] æ²¡æœ‰NaNæˆ–Inf
- [ ] éªŒè¯é›†æŒ‡æ ‡ç¨³æ­¥æå‡
- [ ] å®šæœŸä¿å­˜checkpoint

### è®­ç»ƒå

- [ ] æµ‹è¯•é›†è¯„ä¼°é€šè¿‡
- [ ] æ¨¡å‹å¯ä»¥æ­£å¸¸æ¨ç†
- [ ] æ¨ç†é€Ÿåº¦æ»¡è¶³éœ€æ±‚
- [ ] ä¿å­˜äº†æœ€ä½³æ¨¡å‹å’Œé…ç½®
- [ ] è®°å½•äº†å®éªŒç»“æœ

---

## ğŸ¤ è´¡çŒ®ä¸æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿ï¼š
- æIssue
- æPull Request
- å‚ä¸è®¨è®º

## ğŸ“„ è®¸å¯è¯

MIT License

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€**

å¦‚éœ€æ›´è¯¦ç»†çš„è¯´æ˜ï¼Œè¯·å‚è€ƒï¼š
- `README.md` - å®Œæ•´è‹±æ–‡æ–‡æ¡£
- `å¿«é€Ÿå¼€å§‹.md` - ä¸­æ–‡å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

