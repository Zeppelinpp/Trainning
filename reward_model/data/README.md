# æ•°æ®ç”Ÿæˆè¯´æ˜

## ğŸ“‹ æµç¨‹æ¦‚è§ˆ

### æ­¥éª¤0ï¼šå‡†å¤‡é˜¶æ®µï¼ˆä½¿ç”¨synthetic_gen.pyï¼‰

ç”Ÿæˆå¤šæ ·åŒ–çš„åˆ†ææ¡†æ¶å’Œç³»ç»Ÿæç¤ºè¯ï¼š

```bash
uv run reward_model/data/synthetic_gen.py
```

è¿™ä¼šç”Ÿæˆï¼š
- `analysis_framework/` - å¤šä¸ªä¸åŒçš„åˆ†ææ¡†æ¶ï¼ˆä¸åŒè¡Œä¸šã€ä¸åŒè§†è§’ï¼‰
- `system_prompt/` - å¤šä¸ªç³»ç»Ÿæç¤ºè¯ï¼ˆæ­£é¢/è´Ÿé¢ï¼‰

### æ­¥éª¤1-2ï¼šç”Ÿæˆå¯¹æ¯”å¯¹å¹¶æ‰“åˆ†ï¼ˆä½¿ç”¨synthetic_gen_v2.pyï¼‰

```bash
uv run reward_model/data/synthetic_gen_v2.py
```

#### å®Œæ•´æµç¨‹

1. **åŠ è½½èµ„æº**
   - ä» `analysis_framework/` åŠ è½½æ‰€æœ‰åˆ†ææ¡†æ¶
   - ä» `system_prompt/` åŠ è½½æ‰€æœ‰ç³»ç»Ÿæç¤ºè¯

2. **æ„å»ºè¾“å…¥Prompt**
   ```
   <è§’è‰²å®šä¹‰>
   
   æŒ‡å¼•
   {{ system_prompt }}  # éšæœºé€‰æ‹©
   
   åˆ†ææ¡†æ¶
   {{ analysis_framework }}  # éšæœºé€‰æ‹©
   
   å‚è€ƒæ•°æ®
   {{ data }}
   ```

3. **ç”Ÿæˆé»„é‡‘å“åº”**
   - ä½¿ç”¨å®Œæ•´çš„è¾“å…¥prompt
   - æ·»åŠ ä¼˜è´¨è¾“å‡ºæŒ‡ç¤º
   - ä½æ¸©åº¦ï¼ˆ0.3ï¼‰ä¿è¯è´¨é‡

4. **å—æ§é™çº§**
   - å°†é»„é‡‘å“åº”ä½œä¸ºè¾“å…¥
   - ä½¿ç”¨é™çº§æç¤ºè¯ï¼ˆ5ç§éšæœºé€‰æ‹©ï¼‰
   - ç”Ÿæˆç¼ºé™·å“åº”

5. **AIè£åˆ¤æ‰“åˆ†**
   - ä¸‰ç»´åº¦è¯„åˆ†ï¼ˆ0-4åˆ†ï¼‰ï¼š
     - depth: åˆ†ææ·±åº¦
     - professionalism: ä¸“ä¸šåº¦
     - accuracy: æ•°å€¼å‡†ç¡®æ€§

## ğŸ“ è¾“å‡ºç»“æ„

```
data/
â”œâ”€â”€ dataset/                          # æœ€ç»ˆæ•°æ®é›†è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ comparison_pairs.jsonl       # æœªæ‰“åˆ†çš„å¯¹æ¯”å¯¹
â”‚   â””â”€â”€ comparison_pairs_scored.jsonl # AIè£åˆ¤æ‰“åˆ†åçš„æ•°æ®
â”‚
â”œâ”€â”€ analysis_framework/               # åˆ†ææ¡†æ¶åº“
â”‚   â”œâ”€â”€ qwen-turbo_åˆ¶é€ ä¸š_framework_1.md
â”‚   â”œâ”€â”€ qwen-turbo_åˆ¶é€ ä¸š_framework_2.md
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ system_prompt/                    # ç³»ç»Ÿæç¤ºè¯åº“
    â”œâ”€â”€ positive_qwen-turbo_åˆ¶é€ ä¸š_sys_prompt_1.md
    â”œâ”€â”€ negative_qwen-turbo_åˆ¶é€ ä¸š_sys_prompt_2.md
    â””â”€â”€ ...
```

## ğŸ“Š æ•°æ®æ ¼å¼

### comparison_pairs_scored.jsonl

```json
{
  "prompt": "<è§’è‰²å®šä¹‰>\n\næŒ‡å¼•\n\n{{ system_prompt }}\n\nåˆ†ææ¡†æ¶\n\n{{ analysis_framework }}\n\nå‚è€ƒæ•°æ®\n\n{{ data }}",
  "chosen": "é»„é‡‘å“åº”å…¨æ–‡...",
  "rejected": "ç¼ºé™·å“åº”å…¨æ–‡...",
  "metadata": {
    "field": "åˆ¶é€ ä¸š",
    "model": "qwen-plus",
    "gold_metadata": {...},
    "defect_metadata": {...}
  },
  "scores": {
    "chosen": {
      "depth": 4,
      "professionalism": 3,
      "accuracy": 4
    },
    "rejected": {
      "depth": 1,
      "professionalism": 2,
      "accuracy": 3
    },
    "reasoning": {
      "depth": "é»„é‡‘å“åº”æœ‰æ·±å…¥çš„å½’å› åˆ†æ...",
      "professionalism": "é»„é‡‘å“åº”ä½¿ç”¨ä¸“ä¸šæœ¯è¯­...",
      "accuracy": "é»„é‡‘å“åº”è®¡ç®—ç²¾ç¡®..."
    },
    "overall_assessment": "é»„é‡‘å“åº”åœ¨æ‰€æœ‰ç»´åº¦éƒ½æ˜æ˜¾ä¼˜äºç¼ºé™·å“åº”..."
  }
}
```

## âš™ï¸ é…ç½®è¯´æ˜

### synthetic_gen.py é…ç½®

```python
prompt_pipeline(
    fields=["åˆ¶é€ ä¸š", "æœåŠ¡ä¸š", "é‡‘èä¸š", "æˆ¿åœ°äº§", "ç§‘æŠ€ä¸š"],
    model_configs=[...],  # ä½¿ç”¨å¤šä¸ªæ¨¡å‹å¢åŠ å¤šæ ·æ€§
    samples_per_field=20,  # æ¯ä¸ªè¡Œä¸šç”Ÿæˆ20ç»„
    samples_per_model=5,   # æ¯ç»„ç”Ÿæˆ5ä¸ªå˜ä½“
)
```

### synthetic_gen_v2.py é…ç½®

```python
generate_comparison_dataset(
    fields=["åˆ¶é€ ä¸š", "æœåŠ¡ä¸š", "é‡‘èä¸š", "æˆ¿åœ°äº§", "ç§‘æŠ€ä¸š"],
    model_configs=[...],  # ç”¨äºç”Ÿæˆå“åº”çš„æ¨¡å‹
    n_pairs_per_field=10,  # æ¯ä¸ªè¡Œä¸šç”Ÿæˆ10ä¸ªå¯¹æ¯”å¯¹
    framework_dir="./reward_model/data/analysis_framework/",
    system_prompt_dir="./reward_model/data/system_prompt/",
    output_dir="./reward_model/data/dataset/",
)
```

## ğŸ¯ æ ¸å¿ƒç‰¹ç‚¹

1. **å¤šæ ·æ€§æœ€å¤§åŒ–**
   - å¤šä¸ªåˆ†ææ¡†æ¶ Ã— å¤šä¸ªç³»ç»Ÿæç¤ºè¯ Ã— å¤šä¸ªç”Ÿæˆæ¨¡å‹
   - éšæœºç»„åˆç¡®ä¿æ¯ä¸ªæ ·æœ¬éƒ½ä¸åŒ

2. **å—æ§é™çº§**
   - é»„é‡‘å“åº”ç¡®å®é«˜è´¨é‡
   - ç¼ºé™·å“åº”æœ‰æ˜ç¡®çš„é™çº§ç±»å‹
   - å¯¹æ¯”å¯¹å·®å¼‚å¯æ§ä¸”æ˜æ˜¾

3. **ä¸‰ç»´åº¦è¯„åˆ†**
   - ä¸æ˜¯ç®€å•çš„chosen/rejected
   - æ¯ä¸ªç»´åº¦ç‹¬ç«‹è¯„åˆ†ï¼ˆ0-4åˆ†ï¼‰
   - AIè£åˆ¤æä¾›è¯¦ç»†ç†ç”±

## ğŸ”§ è°ƒä¼˜å»ºè®®

### å¢åŠ æ•°æ®é‡

```python
# synthetic_gen.py
samples_per_field=50  # å¢åŠ åˆ°50ç»„
samples_per_model=10  # æ¯ç»„10ä¸ªå˜ä½“

# synthetic_gen_v2.py  
n_pairs_per_field=50  # æ¯ä¸ªè¡Œä¸š50ä¸ªå¯¹æ¯”å¯¹
```

### ä½¿ç”¨çœŸå®æ•°æ®

ä¿®æ”¹ `SAMPLE_DATA` å˜é‡ï¼Œæ›¿æ¢ä¸ºçœŸå®çš„è´¢åŠ¡æ•°æ®ã€‚

### è°ƒæ•´è¯„åˆ†æ ‡å‡†

ä¿®æ”¹ `add_multidim_scores()` å‡½æ•°ä¸­çš„AIè£åˆ¤æç¤ºè¯ï¼Œè°ƒæ•´è¯„åˆ†æ¡£ä½æˆ–ç»´åº¦ã€‚

## â“ å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆè¦åˆ†ä¸¤æ­¥ç”Ÿæˆï¼Ÿ**

A: ç¬¬ä¸€æ­¥(`synthetic_gen.py`)ç”Ÿæˆå¤šæ ·åŒ–çš„æ¡†æ¶å’Œæç¤ºè¯åº“ï¼Œç¬¬äºŒæ­¥(`synthetic_gen_v2.py`)ä»åº“ä¸­éšæœºç»„åˆï¼Œç¡®ä¿æ¯ä¸ªå¯¹æ¯”å¯¹éƒ½ä¸åŒã€‚

**Q: å¯ä»¥åªè¿è¡Œä¸€æ­¥å—ï¼Ÿ**

A: å¯ä»¥ï¼Œä½†éœ€è¦ç¡®ä¿ `analysis_framework/` å’Œ `system_prompt/` ç›®å½•å·²æœ‰è¶³å¤Ÿçš„æ–‡ä»¶ã€‚

**Q: å¦‚ä½•éªŒè¯æ•°æ®è´¨é‡ï¼Ÿ**

A: ä½¿ç”¨éªŒè¯è„šæœ¬ï¼š
```bash
uv run reward_model/data/validate_multidim_pairs.py \
    reward_model/data/dataset/comparison_pairs_scored.jsonl
```

**Q: ç”Ÿæˆçš„æ•°æ®ä¿å­˜åœ¨å“ªé‡Œï¼Ÿ**

A: ä¿å­˜åœ¨ `reward_model/data/dataset/` ç›®å½•ä¸‹ã€‚

